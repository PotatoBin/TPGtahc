## Project Overview
This project leverages the OpenAI API to intentionally induce hallucinations in an AI, leading it to share incorrect knowledge and flawed conclusions as a form of media art. Through interacting with the AI, users are encouraged to reflect on the nature of information distortion, interpretation, and the reliability of AI-generated content. The project uses intentional hallucinations to explore the creative potential of artificial intelligence and its possible pitfalls in reasoning and information accuracy.

## Key Features
- **AI Hallucination**: Utilizes the OpenAI API to intentionally produce misinformation and flawed reasoning in AI interactions.
- **Interactive UI**: Users can ask questions and engage with the AI, experiencing distorted information and misinterpreted knowledge.
- **Media Art Experience**: Combines visual media with intentional misinformation to encourage users to reflect on the potential for AI-driven information distortion.
